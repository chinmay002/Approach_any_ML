{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cb731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "660491c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cat_var_train.csv')\n",
    "#df = df[['bin_0','bin_1','nom_0','nom_1','ord_0','ord_1','ord_2','month','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "541119db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>None</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id bin_0 bin_1 bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0     0     0     0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1     1     1     0     F     Y   Red       Star  Axolotl        None   \n",
       "2   2     0     1     0     F     N   Red       None  Hamster      Canada   \n",
       "3   3  None     0     0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4     0  None     0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4 ord_5 day month  \\\n",
       "0  ...  02e7c8990     3  Contributor       Hot     c     U    Pw   6     3   \n",
       "1  ...  f37df64af     3  Grandmaster      Warm     e     X    pE   7     7   \n",
       "2  ...       None     3         None  Freezing     n     P    eN   5     9   \n",
       "3  ...  f9d456e57     1       Novice  Lava Hot     a     C  None   3     3   \n",
       "4  ...  c5361037c     3  Grandmaster      Cold     h     C    OZ   5    12   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.fillna('None',inplace =True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d974cfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_0--->0.0     528377\n",
      "1.0      53729\n",
      "None     17894\n",
      "Name: bin_0, dtype: int64\n",
      "\n",
      "bin_1--->0.0     474018\n",
      "1.0     107979\n",
      "None     18003\n",
      "Name: bin_1, dtype: int64\n",
      "\n",
      "nom_0--->Red      323286\n",
      "Blue     205861\n",
      "Green     52601\n",
      "None      18252\n",
      "Name: nom_0, dtype: int64\n",
      "\n",
      "nom_1--->Triangle     164190\n",
      "Polygon      152563\n",
      "Trapezoid    119438\n",
      "Circle       104995\n",
      "Square        26503\n",
      "None          18156\n",
      "Star          14155\n",
      "Name: nom_1, dtype: int64\n",
      "\n",
      "ord_0--->1.0     227917\n",
      "3.0     197798\n",
      "2.0     155997\n",
      "None     18288\n",
      "Name: ord_0, dtype: int64\n",
      "\n",
      "ord_1--->Novice         160597\n",
      "Expert         139677\n",
      "Contributor    109821\n",
      "Grandmaster     95866\n",
      "Master          75998\n",
      "None            18041\n",
      "Name: ord_1, dtype: int64\n",
      "\n",
      "ord_2--->Freezing       142726\n",
      "Warm           124239\n",
      "Cold            97822\n",
      "Boiling Hot     84790\n",
      "Hot             67508\n",
      "Lava Hot        64840\n",
      "None            18075\n",
      "Name: ord_2, dtype: int64\n",
      "\n",
      "month--->8.0     79245\n",
      "3.0     70160\n",
      "5.0     68906\n",
      "12.0    68340\n",
      "6.0     60478\n",
      "7.0     53480\n",
      "1.0     52154\n",
      "11.0    51165\n",
      "2.0     40700\n",
      "9.0     20620\n",
      "None    17988\n",
      "4.0     14614\n",
      "10.0     2150\n",
      "Name: month, dtype: int64\n",
      "\n",
      "target--->0    487677\n",
      "1    112323\n",
      "Name: target, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f'{col}--->{df[col].value_counts()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2feea45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hot', 'Warm', 'Freezing', 'Lava Hot', 'Cold', 'Boiling Hot',\n",
       "       'None'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ord_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d68f5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"Freezing\": 0, \"Warm\": 1,\"Cold\": 2,\"Boiling Hot\": 3,\"Hot\": 4,\"Lava Hot\": 5,'None':6}\n",
    "\n",
    "df.loc[:,'ord_2'] = df.ord_2.map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0e44b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142726\n",
       "1    124239\n",
       "2     97822\n",
       "3     84790\n",
       "4     67508\n",
       "5     64840\n",
       "6     18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ord_2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0bb830",
   "metadata": {},
   "source": [
    "The problem with label encoding for linear algorithms is that it introduces an inherent ordering between the categories, which may not necessarily reflect the true nature of the data. For example, if we encode the categories \"red\", \"green\", and \"blue\" as 1, 2, and 3, respectively, a linear algorithm will assume that \"green\" is closer to \"red\" than \"blue\", which may not be true in reality.\n",
    "\n",
    "This can lead to biased or incorrect results when using linear models, as the model may overweight or underweight certain categories based on their assigned numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "faa3f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#sparse Matrix\n",
    "\n",
    "example = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1]\n",
    "])\n",
    "print(example.nbytes)\n",
    "\n",
    "#we can make this as dic of (row,index) = value\n",
    "# (0,2)   1\n",
    "# (1,0)   1\n",
    "# (2,1)   1\n",
    "# (2,2)   1\n",
    "\n",
    "from scipy import sparse\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oneHotEncoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffb24c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dense matrix 72\n",
      "size of sparse array:12\n"
     ]
    }
   ],
   "source": [
    "example = np.array(\n",
    "                    [\n",
    "                    [0, 0, 0, 0, 1, 0],\n",
    "                    [0, 1, 0, 0, 0, 0],\n",
    "                    [1, 0, 0, 0, 0, 0]\n",
    "                    ]\n",
    "                    )\n",
    "\n",
    "print(f'Size of the dense matrix {example.nbytes}')\n",
    "sparse_ex = sparse.csr_matrix(example)\n",
    "\n",
    "print(f'size of sparse array:{sparse_ex.data.nbytes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d225edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          67508\n",
       "1         124239\n",
       "2         142726\n",
       "3          64840\n",
       "4          97822\n",
       "5          67508\n",
       "6          97822\n",
       "7          97822\n",
       "8          84790\n",
       "9          64840\n",
       "10         67508\n",
       "11         67508\n",
       "12        142726\n",
       "13         64840\n",
       "14        142726\n",
       "15         67508\n",
       "16         84790\n",
       "17        124239\n",
       "18         67508\n",
       "19         84790\n",
       "20        142726\n",
       "21         67508\n",
       "22         67508\n",
       "23        124239\n",
       "24         84790\n",
       "25        124239\n",
       "26        142726\n",
       "27         97822\n",
       "28        124239\n",
       "29         97822\n",
       "           ...  \n",
       "599970    142726\n",
       "599971    142726\n",
       "599972    142726\n",
       "599973     97822\n",
       "599974     84790\n",
       "599975    142726\n",
       "599976     64840\n",
       "599977     67508\n",
       "599978    142726\n",
       "599979     84790\n",
       "599980     67508\n",
       "599981     64840\n",
       "599982    124239\n",
       "599983     97822\n",
       "599984    142726\n",
       "599985    124239\n",
       "599986    142726\n",
       "599987    124239\n",
       "599988     64840\n",
       "599989     84790\n",
       "599990    142726\n",
       "599991    124239\n",
       "599992    142726\n",
       "599993    142726\n",
       "599994     97822\n",
       "599995    142726\n",
       "599996     84790\n",
       "599997    142726\n",
       "599998    124239\n",
       "599999     84790\n",
       "Name: id, Length: 600000, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['ord_2'])['id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76f89c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>15634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Cold</td>\n",
       "      <td>17734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>26082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>12428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>None</td>\n",
       "      <td>3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Warm</td>\n",
       "      <td>22774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>19477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Cold</td>\n",
       "      <td>22956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>33249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Hot</td>\n",
       "      <td>15792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Expert</td>\n",
       "      <td>None</td>\n",
       "      <td>4225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Warm</td>\n",
       "      <td>28900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>13623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>15464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>22818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>10805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>None</td>\n",
       "      <td>2894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Master</td>\n",
       "      <td>Cold</td>\n",
       "      <td>12364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Master</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>18035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Master</td>\n",
       "      <td>Hot</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Master</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Master</td>\n",
       "      <td>None</td>\n",
       "      <td>2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>15734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>Cold</td>\n",
       "      <td>3033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>Hot</td>\n",
       "      <td>2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>Warm</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Cold</td>\n",
       "      <td>26271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>38233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Hot</td>\n",
       "      <td>17850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>17373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Novice</td>\n",
       "      <td>None</td>\n",
       "      <td>4889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Warm</td>\n",
       "      <td>33263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_1        ord_2     id\n",
       "0   Contributor  Boiling Hot  15634\n",
       "1   Contributor         Cold  17734\n",
       "2   Contributor     Freezing  26082\n",
       "3   Contributor          Hot  12428\n",
       "4   Contributor     Lava Hot  11919\n",
       "5   Contributor         None   3250\n",
       "6   Contributor         Warm  22774\n",
       "7        Expert  Boiling Hot  19477\n",
       "8        Expert         Cold  22956\n",
       "9        Expert     Freezing  33249\n",
       "10       Expert          Hot  15792\n",
       "11       Expert     Lava Hot  15078\n",
       "12       Expert         None   4225\n",
       "13       Expert         Warm  28900\n",
       "14  Grandmaster  Boiling Hot  13623\n",
       "15  Grandmaster         Cold  15464\n",
       "16  Grandmaster     Freezing  22818\n",
       "17  Grandmaster          Hot  10805\n",
       "18  Grandmaster     Lava Hot  10363\n",
       "19  Grandmaster         None   2894\n",
       "20  Grandmaster         Warm  19899\n",
       "21       Master  Boiling Hot  10800\n",
       "22       Master         Cold  12364\n",
       "23       Master     Freezing  18035\n",
       "24       Master          Hot   8594\n",
       "25       Master     Lava Hot   8209\n",
       "26       Master         None   2262\n",
       "27       Master         Warm  15734\n",
       "28         None  Boiling Hot   2538\n",
       "29         None         Cold   3033\n",
       "30         None     Freezing   4309\n",
       "31         None          Hot   2039\n",
       "32         None     Lava Hot   1898\n",
       "33         None         None    555\n",
       "34         None         Warm   3669\n",
       "35       Novice  Boiling Hot  22718\n",
       "36       Novice         Cold  26271\n",
       "37       Novice     Freezing  38233\n",
       "38       Novice          Hot  17850\n",
       "39       Novice     Lava Hot  17373\n",
       "40       Novice         None   4889\n",
       "41       Novice         Warm  33263"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['ord_1','ord_2'])['id'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb6d3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_feat'] = df.ord_1.astype(str)+'_'+df.ord_2.astype(str)+'_'+df.ord_3.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56692be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot_c\n",
       "1                Grandmaster_Warm_e\n",
       "2                   None_Freezing_n\n",
       "3                 Novice_Lava Hot_a\n",
       "4                Grandmaster_Cold_h\n",
       "5                      Expert_Hot_b\n",
       "6                Grandmaster_Cold_c\n",
       "7                     Expert_Cold_b\n",
       "8              Novice_Boiling Hot_c\n",
       "9            Contributor_Lava Hot_n\n",
       "10                     Novice_Hot_b\n",
       "11                Contributor_Hot_b\n",
       "12                Novice_Freezing_a\n",
       "13           Contributor_Lava Hot_h\n",
       "14                Master_Freezing_d\n",
       "15                Contributor_Hot_k\n",
       "16             Novice_Boiling Hot_h\n",
       "17                    Novice_Warm_g\n",
       "18                     Master_Hot_h\n",
       "19        Grandmaster_Boiling Hot_n\n",
       "20                Novice_Freezing_h\n",
       "21                Contributor_Hot_h\n",
       "22                     Master_Hot_k\n",
       "23                    Novice_Warm_n\n",
       "24        Grandmaster_Boiling Hot_b\n",
       "25                    Expert_Warm_c\n",
       "26           Grandmaster_Freezing_o\n",
       "27                    Novice_Cold_a\n",
       "28                    Novice_Warm_a\n",
       "29                    Expert_Cold_a\n",
       "                    ...            \n",
       "599970       Contributor_Freezing_a\n",
       "599971       Contributor_Freezing_a\n",
       "599972       Grandmaster_Freezing_d\n",
       "599973           Contributor_Cold_h\n",
       "599974         Master_Boiling Hot_d\n",
       "599975            Expert_Freezing_n\n",
       "599976       Grandmaster_Lava Hot_h\n",
       "599977                 Novice_Hot_n\n",
       "599978       Contributor_Freezing_f\n",
       "599979         Expert_Boiling Hot_d\n",
       "599980                 Master_Hot_o\n",
       "599981       Contributor_Lava Hot_c\n",
       "599982           Contributor_Warm_n\n",
       "599983                Expert_Cold_c\n",
       "599984            Novice_Freezing_c\n",
       "599985                Novice_Warm_h\n",
       "599986            Expert_Freezing_k\n",
       "599987                Novice_Warm_d\n",
       "599988            Master_Lava Hot_k\n",
       "599989         Master_Boiling Hot_k\n",
       "599990            Novice_Freezing_i\n",
       "599991           Contributor_Warm_f\n",
       "599992            Novice_Freezing_d\n",
       "599993       Contributor_Freezing_n\n",
       "599994           Grandmaster_Cold_f\n",
       "599995            Novice_Freezing_a\n",
       "599996         Novice_Boiling Hot_n\n",
       "599997       Contributor_Freezing_n\n",
       "599998                Master_Warm_m\n",
       "599999    Contributor_Boiling Hot_b\n",
       "Name: new_feat, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912185d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3956575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "test['target'] = -1\n",
    "\n",
    "data = pd.concat([df,test]).reset_index(drop=True)\n",
    "features = [x for x in df.columns if x not in ['id','target']]\n",
    "\n",
    "for feat in features:\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    temp_col = data[feat].fillna('None').astype(str).values\n",
    "    \n",
    "    data.loc[:,feat] = lbl_enc.fit_transform(temp_col)\n",
    "    \n",
    "train_df = data[data.target!=-1].reset_index(drop=True)\n",
    "test_df = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf59144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this trick works when we already know the test dataset.But during live model prediction\n",
    "#if we introduce a new categroy in training , we wont be able to predcit \n",
    "#to avoid this situdation we use ;;unknown category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52faae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "None            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if during testing we have not seen the data, we can make them as NOne.\n",
    "#lika a nlp , We define Vocab size and if word not present , we consider as UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a620cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "None    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ord_4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "650f46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some value occur only in 1000 and some occur more than 30K. These are rare words\n",
    "#we can specify a condition and make them Rare words\n",
    "\n",
    "df.loc[df['ord_4'].value_counts()[df['ord_4']].values < 2000,'ord_4']='RARE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f95bebe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "None    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "RARE     3607\n",
       "G        3404\n",
       "V        3107\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca11b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this ensure that all unseen data will be mapped as Rare in test and missing\n",
    "#values as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "19439581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['target'] !=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90d13a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba150e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kfold'] = -1\n",
    "\n",
    "#randomize the things\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#featch labels\n",
    "y = df.target.values\n",
    "\n",
    "#initiale the kfold class from model_Selection module\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "for f,(t_,v_) in enumerate(kf.split(X=df,y=y)):# (ind x and ind y)\n",
    "    #print(v_)\n",
    "    df.loc[v_,'kfold'] = f\n",
    "    #print(df['kfold'].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21b2165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cat_train_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "17e22dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "      <th>new_feat</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Dog</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>mD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Expert_Lava Hot_e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Cold</td>\n",
       "      <td>n</td>\n",
       "      <td>K</td>\n",
       "      <td>jf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Contributor_Cold_n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>P</td>\n",
       "      <td>Nh</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contributor_Hot_h</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>K</td>\n",
       "      <td>MU</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Novice_Lava Hot_a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>Master</td>\n",
       "      <td>Cold</td>\n",
       "      <td>n</td>\n",
       "      <td>X</td>\n",
       "      <td>Mg</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Master_Cold_n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id bin_0 bin_1 bin_2 bin_3 bin_4 nom_0      nom_1    nom_2    nom_3  \\\n",
       "0  207092   0.0   0.0  None     F     N   Red   Triangle      Dog     None   \n",
       "1  112348   0.0   0.0   1.0     T     Y   Red    Polygon  Hamster  Finland   \n",
       "2  244025   0.0   1.0   0.0     T     N  Blue  Trapezoid     Lion  Finland   \n",
       "3   11891   0.0   0.0   0.0     T     N  Blue    Polygon  Hamster     None   \n",
       "4  393254   0.0   1.0   1.0     F     N   Red     Circle  Hamster   Russia   \n",
       "\n",
       "   ...        ord_1     ord_2 ord_3 ord_4 ord_5  day month target  \\\n",
       "0  ...       Expert  Lava Hot     e     X    mD  3.0   6.0      0   \n",
       "1  ...  Contributor      Cold     n     K    jf  2.0   8.0      1   \n",
       "2  ...  Contributor       Hot     h     P    Nh  2.0   5.0      0   \n",
       "3  ...       Novice  Lava Hot     a     K    MU  5.0   5.0      0   \n",
       "4  ...       Master      Cold     n     X    Mg  6.0   5.0      1   \n",
       "\n",
       "             new_feat kfold  \n",
       "0   Expert_Lava Hot_e     0  \n",
       "1  Contributor_Cold_n     0  \n",
       "2   Contributor_Hot_h     0  \n",
       "3   Novice_Lava Hot_a     0  \n",
       "4       Master_Cold_n     0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('cat_train_folds.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "711d7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    97536\n",
      "1    22464\n",
      "Name: target, dtype: int64\n",
      "0    97536\n",
      "1    22464\n",
      "Name: target, dtype: int64\n",
      "0    97535\n",
      "1    22465\n",
      "Name: target, dtype: int64\n",
      "0    97535\n",
      "1    22465\n",
      "Name: target, dtype: int64\n",
      "0    97535\n",
      "1    22465\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for val in df1['kfold'].unique():\n",
    "    print(df1[df1['kfold']==val]['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f97df478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    120001\n",
       "4    120000\n",
       "3    120000\n",
       "2    120000\n",
       "1    120000\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['kfold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "de526c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model,metrics,preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "\n",
    "    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnâ€™t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    \n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat([df_train[features], df_valid[features]],axis=0)\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    print(f'shape of x_trian {x_train.shape}')\n",
    "    print(f'shape of x_trian {df_train.target.values.shape}')\n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    print(f'shape of x_valid {x_valid.shape}')\n",
    "    \n",
    "    # initialize Logistic Regression model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7b8029db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "0.7841683176021266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "run(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "872bb02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7841683176021266\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843398350126315\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7864437188172995\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876077315623121\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "0.784524760587749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinmay\\anaconda3\\envs\\envpytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "for fold_ in range(5):\n",
    "    run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b52db27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1148509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn import decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "efc9f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "Fold = 0, AUC = 0.7055380027280306\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "Fold = 1, AUC = 0.7027274449395352\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "Fold = 2, AUC = 0.7080941468037332\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "Fold = 3, AUC = 0.7105896543886481\n",
      "shape of x_trian (480000, 6394)\n",
      "shape of x_trian (480000,)\n",
      "shape of x_valid (120000, 6394)\n",
      "Fold = 4, AUC = 0.7075838864922179\n"
     ]
    }
   ],
   "source": [
    "def run(fold):\n",
    "    \n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "\n",
    "    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n",
    "    \n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnâ€™t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    \n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    \n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat([df_train[features], df_valid[features]],axis=0)\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    print(f'shape of x_trian {x_train.shape}')\n",
    "    print(f'shape of x_trian {df_train.target.values.shape}')\n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    print(f'shape of x_valid {x_valid.shape}')\n",
    "    \n",
    "    #initialize Truncated Data\n",
    "    #reducing the data to 120 components\n",
    "    \n",
    "    svd = decomposition.TruncatedSVD(n_components=120)#give 120 dim like PCA\n",
    "    full_sparse = sparse.vstack((x_train,x_valid))\n",
    "    svd.fit(full_sparse)\n",
    "    \n",
    "    x_train = svd.transform(x_train)\n",
    "    x_valid = svd.transform(x_valid)\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "                               \n",
    "        \n",
    "for fold_ in range(5):\n",
    "    run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "407df5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=120)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38daa040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(5, 3)\n",
    "\n",
    "# Perform SVD\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "X_svd = svd.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aab83991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40337934,  0.08062692],\n",
       "       [ 1.45688399, -0.09467621],\n",
       "       [ 0.80633313,  0.28022834],\n",
       "       [ 0.39994474,  0.38354554],\n",
       "       [ 0.89610252, -0.30570765]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "537906d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.21087956e+00, -7.83019293e-16],\n",
       "       [-9.48023899e-17,  1.00000000e+00],\n",
       "       [ 4.99780755e+00,  1.78195086e-16],\n",
       "       [-1.51683824e-16,  5.00000000e+00]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse = sparse.csr_matrix([[1, 0, 2], [0, 1, 0], [3, 0, 4], [0, 5, 0]])\n",
    "\n",
    "# Initialize and fit SVD on the sparse matrix\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "svd.fit_transform(X_sparse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
